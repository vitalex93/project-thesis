{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\avitsas\\Anaconda3\\envs\\project\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ReportGenerator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Payment predictions 1': 'Provide a report that displays the number of accounts with running settlements for the Earth portfolio, their expected monthly \\\n",
    "                  payments at the end of the examined month and their actual monthly payments per DCA, for September 2020. ',\n",
    "    'Payment predictions 2': 'Provide a report that displays the number of accounts not in running settlements for the Earth portfolio, their expected monthly \\\n",
    "                  payments at the end of the examined month and their actual monthly payments per DCA, for September 2020.',\n",
    "    'Report 6_1': 'Provide the number of customers with active and running settlements of types Settlement, Preappoved, Resch to Sett,\\\n",
    "                  Out of Mandate Had Settlement and null on the Earth portfolio, the corresponding number of applications, \\\n",
    "                  the initial settlement amount, discount amount and future instalments per asset class and DCA, for September 2020.',\n",
    "    'Report 6_2': 'Provide the distribution of the number of active and running settlements of types Settlement, Preappoved, Resch to Sett, \\\n",
    "                  Out of Mandate Had Settlement and null on the Earth portfolio based on their duration on the following bins: up to 6 months, \\\n",
    "                  7 to 12 months, 13 to 36 months, 37 to 72 months, 72 to 108 months and more than 109 months. The analysis should be \\\n",
    "                  performane per asset class and DCA, for September 2020.',\n",
    "    'Report 8_2': 'Create a report that shows the number of pending settlement applications (in status Review, Working, \\\n",
    "                  Quality Control, For approval and Approved) submitted up to the end of the previous month, their approved amount,\\\n",
    "                  the average pending days  and their entry principal and balance, for September 2020  per DCA and application type. \\\n",
    "                  The report should be produced on Earth portfolio.',\n",
    "    'Report 8_1': 'Create a report that shows the number of settlement applications submitted during the month, \\\n",
    "                  their approved amount and their entry principal and balance, for September 2020  per DCA and application type. \\\n",
    "                  The report should be produced on Earth portfolio.',\n",
    "    'Report 8_3': 'Create a report that shows the number of settlement applications approved during the month, their approved amount, \\\n",
    "                  the written off balance, the average days to approval, their average and median duration and their entry principal and balance, \\\n",
    "                  for September 2020 per DCA and application type. The report should be produced on Earth portfolio.',\n",
    "    'Report 8_4': 'Create a report that shows the number of settlement applications rejected during the month, their approved amount, \\\n",
    "                  the average days to rejection, their entry principal and entry balance, for September 2020 per DCA \\\n",
    "                  and application type. The report should be produced on Earth portfolio.'  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = ReportGenerator(description=data['Payment predictions 1'], model='sbert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MEAS_APPL_AMT_PAYMENTS_TOTAL']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Payment predictions 1': 0.0} precision\n",
      "{'Payment predictions 1': 0.0} recall\n",
      "{'Payment predictions 2': 0.0} precision\n",
      "{'Payment predictions 2': 0.0} recall\n",
      "{'Report 6_1': 75.0} precision\n",
      "{'Report 6_1': 75.0} recall\n",
      "{'Report 6_2': 71.42857142857143} precision\n",
      "{'Report 6_2': 83.33333333333334} recall\n",
      "{'Report 8_2': 60.0} precision\n",
      "{'Report 8_2': 75.0} recall\n",
      "{'Report 8_1': 75.0} precision\n",
      "{'Report 8_1': 100.0} recall\n",
      "{'Report 8_3': 71.42857142857143} precision\n",
      "{'Report 8_3': 71.42857142857143} recall\n",
      "{'Report 8_4': 60.0} precision\n",
      "{'Report 8_4': 60.0} recall\n"
     ]
    }
   ],
   "source": [
    "for report, description in data.items():\n",
    "    rg = ReportGenerator(description=description, model='sbert')\n",
    "    print(rg.evaluation(metric='precision', report=report), 'precision')\n",
    "    print(rg.evaluation(metric='recall', report=report), 'recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Payment predictions 1': 0.0} precision\n",
      "{'Payment predictions 1': 0.0} recall\n",
      "{'Payment predictions 2': 0.0} precision\n",
      "{'Payment predictions 2': 0.0} recall\n",
      "{'Report 6_1': 75.0} precision\n",
      "{'Report 6_1': 75.0} recall\n",
      "{'Report 6_2': 28.57142857142857} precision\n",
      "{'Report 6_2': 33.33333333333333} recall\n",
      "{'Report 8_2': 40.0} precision\n",
      "{'Report 8_2': 50.0} recall\n",
      "{'Report 8_1': 50.0} precision\n",
      "{'Report 8_1': 66.66666666666666} recall\n",
      "{'Report 8_3': 57.14285714285714} precision\n",
      "{'Report 8_3': 57.14285714285714} recall\n",
      "{'Report 8_4': 60.0} precision\n",
      "{'Report 8_4': 60.0} recall\n"
     ]
    }
   ],
   "source": [
    "for report, description in data.items():\n",
    "    rg = ReportGenerator(description=description, model='bow')\n",
    "    print(rg.evaluation(metric='precision', report=report), 'precision')\n",
    "    print(rg.evaluation(metric='recall', report=report), 'recall')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Payment predictions 1': 0.0} precision\n",
      "{'Payment predictions 1': 0.0} recall\n",
      "{'Payment predictions 2': 0.0} precision\n",
      "{'Payment predictions 2': 0.0} recall\n",
      "{'Report 6_1': 75.0} precision\n",
      "{'Report 6_1': 75.0} recall\n",
      "{'Report 6_2': 85.71428571428571} precision\n",
      "{'Report 6_2': 100.0} recall\n",
      "{'Report 8_2': 40.0} precision\n",
      "{'Report 8_2': 50.0} recall\n",
      "{'Report 8_1': 50.0} precision\n",
      "{'Report 8_1': 66.66666666666666} recall\n",
      "{'Report 8_3': 42.857142857142854} precision\n",
      "{'Report 8_3': 42.857142857142854} recall\n",
      "{'Report 8_4': 60.0} precision\n",
      "{'Report 8_4': 60.0} recall\n"
     ]
    }
   ],
   "source": [
    "for report, description in data.items():\n",
    "    rg = ReportGenerator(description=description, model='tfidf')\n",
    "    print(rg.evaluation(metric='precision', report=report), 'precision')\n",
    "    print(rg.evaluation(metric='recall', report=report), 'recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Payment predictions 1': 0.0} precision\n",
      "{'Payment predictions 1': 0.0} recall\n",
      "{'Payment predictions 2': 0.0} precision\n",
      "{'Payment predictions 2': 0.0} recall\n",
      "{'Report 6_1': 75.0} precision\n",
      "{'Report 6_1': 75.0} recall\n",
      "{'Report 6_2': 0.0} precision\n",
      "{'Report 6_2': 0.0} recall\n",
      "{'Report 8_2': 60.0} precision\n",
      "{'Report 8_2': 75.0} recall\n",
      "{'Report 8_1': 75.0} precision\n",
      "{'Report 8_1': 100.0} recall\n",
      "{'Report 8_3': 100.0} precision\n",
      "{'Report 8_3': 100.0} recall\n",
      "{'Report 8_4': 60.0} precision\n",
      "{'Report 8_4': 60.0} recall\n"
     ]
    }
   ],
   "source": [
    "for report, description in data.items():\n",
    "    rg = ReportGenerator(description=description, model='bow_bigrams')\n",
    "    print(rg.evaluation(metric='precision', report=report), 'precision')\n",
    "    print(rg.evaluation(metric='recall', report=report), 'recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Payment predictions 1': 0.0} precision\n",
      "{'Payment predictions 1': 0.0} recall\n",
      "{'Payment predictions 2': 100.0} precision\n",
      "{'Payment predictions 2': 50.0} recall\n",
      "{'Report 6_1': 25.0} precision\n",
      "{'Report 6_1': 25.0} recall\n",
      "{'Report 6_2': 57.14285714285714} precision\n",
      "{'Report 6_2': 66.66666666666666} recall\n",
      "{'Report 8_2': 20.0} precision\n",
      "{'Report 8_2': 25.0} recall\n",
      "{'Report 8_1': 25.0} precision\n",
      "{'Report 8_1': 33.33333333333333} recall\n",
      "{'Report 8_3': 14.285714285714285} precision\n",
      "{'Report 8_3': 14.285714285714285} recall\n",
      "{'Report 8_4': 20.0} precision\n",
      "{'Report 8_4': 20.0} recall\n"
     ]
    }
   ],
   "source": [
    "for report, description in data.items():\n",
    "    rg = ReportGenerator(description=description, model='tfidf_bigrams')\n",
    "    print(rg.evaluation(metric='precision', report=report), 'precision')\n",
    "    print(rg.evaluation(metric='recall', report=report), 'recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Payment predictions 1': 0.0} precision\n",
      "{'Payment predictions 1': 0.0} recall\n",
      "{'Payment predictions 2': 0.0} precision\n",
      "{'Payment predictions 2': 0.0} recall\n",
      "{'Report 6_1': 75.0} precision\n",
      "{'Report 6_1': 75.0} recall\n",
      "{'Report 6_2': 0.0} precision\n",
      "{'Report 6_2': 0.0} recall\n",
      "{'Report 8_2': 60.0} precision\n",
      "{'Report 8_2': 75.0} recall\n",
      "{'Report 8_1': 75.0} precision\n",
      "{'Report 8_1': 100.0} recall\n",
      "{'Report 8_3': 100.0} precision\n",
      "{'Report 8_3': 100.0} recall\n",
      "{'Report 8_4': 60.0} precision\n",
      "{'Report 8_4': 60.0} recall\n"
     ]
    }
   ],
   "source": [
    "for report, description in data.items():\n",
    "    rg = ReportGenerator(description=description, model='bow_trigrams')\n",
    "    print(rg.evaluation(metric='precision', report=report), 'precision')\n",
    "    print(rg.evaluation(metric='recall', report=report), 'recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Payment predictions 1': 0.0} precision\n",
      "{'Payment predictions 1': 0.0} recall\n",
      "{'Payment predictions 2': 0.0} precision\n",
      "{'Payment predictions 2': 0.0} recall\n",
      "{'Report 6_1': 75.0} precision\n",
      "{'Report 6_1': 75.0} recall\n",
      "{'Report 6_2': 0.0} precision\n",
      "{'Report 6_2': 0.0} recall\n",
      "{'Report 8_2': 60.0} precision\n",
      "{'Report 8_2': 75.0} recall\n",
      "{'Report 8_1': 75.0} precision\n",
      "{'Report 8_1': 100.0} recall\n",
      "{'Report 8_3': 100.0} precision\n",
      "{'Report 8_3': 100.0} recall\n",
      "{'Report 8_4': 60.0} precision\n",
      "{'Report 8_4': 60.0} recall\n"
     ]
    }
   ],
   "source": [
    "for report, description in data.items():\n",
    "    rg = ReportGenerator(description=description, model='tfidf_trigrams')\n",
    "    print(rg.evaluation(metric='precision', report=report), 'precision')\n",
    "    print(rg.evaluation(metric='recall', report=report), 'recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Payment predictions 1': 0.0} precision\n",
      "{'Payment predictions 1': 0.0} recall\n",
      "{'Payment predictions 2': 0.0} precision\n",
      "{'Payment predictions 2': 0.0} recall\n",
      "{'Report 6_1': 75.0} precision\n",
      "{'Report 6_1': 75.0} recall\n",
      "{'Report 6_2': 83.33333333333334} precision\n",
      "{'Report 6_2': 83.33333333333334} recall\n",
      "{'Report 8_2': 40.0} precision\n",
      "{'Report 8_2': 50.0} recall\n",
      "{'Report 8_1': 50.0} precision\n",
      "{'Report 8_1': 66.66666666666666} recall\n",
      "{'Report 8_3': 42.857142857142854} precision\n",
      "{'Report 8_3': 42.857142857142854} recall\n",
      "{'Report 8_4': 80.0} precision\n",
      "{'Report 8_4': 80.0} recall\n"
     ]
    }
   ],
   "source": [
    "for report, description in data.items():\n",
    "    rg = ReportGenerator(description=description, model='word2vec-google-news-300')\n",
    "    print(rg.evaluation(metric='precision', report=report), 'precision')\n",
    "    print(rg.evaluation(metric='recall', report=report), 'recall')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
